from transformers import BlipProcessor, BlipForConditionalGeneration
from transformers import BlipForQuestionAnswering
from PIL import Image

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  ğŸ”§ CHANGE THESE FOR YOUR EXAM                                              â•‘
# â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
# â•‘  IMAGE_PATH   â†’ Path to your image file                                     â•‘
# â•‘                 Windows: use r"C:\path\to\image.jpg"                        â•‘
# â•‘                 Or relative: "images/test.jpg"                              â•‘
# â•‘  TEXT_PROMPT  â†’ Starting text for conditional caption                       â•‘
# â•‘                 Examples: "a photo of", "this is", "I see"                  â•‘
# â•‘  QUESTION     â†’ Question to ask about the image                             â•‘
# â•‘                 Examples: "What is in the image?", "What color is it?"      â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

IMAGE_PATH = r"images/test.jpg"       # â† CHANGE to your image path!
TEXT_PROMPT = "a photo of"            # â† CHANGE if professor specifies
QUESTION = "What is in the image?"    # â† CHANGE to your question


# Load models (don't change these!)
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
caption_model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
qa_model = BlipForQuestionAnswering.from_pretrained("Salesforce/blip-vqa-base")

# Load image
image = Image.open(IMAGE_PATH)


def basic_caption(img):
    """Generates caption without any prompt - just describes what it sees"""
    inputs = processor(img, return_tensors="pt")
    outputs = caption_model.generate(**inputs)
    return processor.decode(outputs[0], skip_special_tokens=True)


def conditional_caption(img, text_prompt):
    """Generates caption starting with your text_prompt"""
    inputs = processor(img, text_prompt, return_tensors="pt")
    outputs = caption_model.generate(**inputs)
    return processor.decode(outputs[0], skip_special_tokens=True)


def visual_qa(img, question):
    """Answers a question about the image"""
    inputs = processor(img, question, return_tensors="pt")
    outputs = qa_model.generate(**inputs)
    return processor.decode(outputs[0], skip_special_tokens=True)


if __name__ == '__main__':
    print(f"Basic Caption: {basic_caption(image)}")
    print(f"Conditional: {conditional_caption(image, TEXT_PROMPT)}")
    print(f"Q: {QUESTION}")
    print(f"A: {visual_qa(image, QUESTION)}")